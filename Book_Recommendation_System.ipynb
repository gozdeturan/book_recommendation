{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Recommendation System\n",
    "\n",
    "**Author:** Gozde Turan\n",
    "\n",
    "Submitted to Fellowship.ai at 12 August 2018\n",
    "\n",
    "In this work, I will build a book recommendation system using the data provided in following link('http://www2.informatik.uni-freiburg.de/~cziegler/BX/'). I will apply 5 basic steps to accomplish the task.\n",
    "1. Exploring the data provided\n",
    "2. Filtering datasets\n",
    "2. Splitting training and test data\n",
    "3. Evaluating the algorithms and techniques\n",
    "4. Creating a function to provide recommendations for a given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore warnings on runtime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pandas library helps to read and parse csv files easily\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "Firstly, I will read all csv files (BX-Books.csv, BX-Users.csv and BX-Book-Ratings.csv) from the given destinations and print 5 row from each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>BookAuthor</th>\n",
       "      <th>YearOfPublication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ImageUrlS</th>\n",
       "      <th>ImageUrlM</th>\n",
       "      <th>ImageUrlL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                          BookTitle  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "             BookAuthor YearOfPublication                   Publisher  \\\n",
       "0    Mark P. O. Morford              2002     Oxford University Press   \n",
       "1  Richard Bruce Wright              2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este              1991             HarperPerennial   \n",
       "3      Gina Bari Kolata              1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber              1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                           ImageUrlS  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                           ImageUrlM  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                           ImageUrlL  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read books\n",
    "books = pd.read_csv('/Users/gozdeturan/Downloads/BX-CSV-Dump/BX-Books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "# Set columns for books\n",
    "books.columns = ['ISBN', 'BookTitle', 'BookAuthor', 'YearOfPublication', 'Publisher', 'ImageUrlS', 'ImageUrlM', 'ImageUrlL']\n",
    "# Print first 5 books to see a sample content\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID                            Location   Age\n",
       "0       1                  nyc, new york, usa   NaN\n",
       "1       2           stockton, california, usa  18.0\n",
       "2       3     moscow, yukon territory, russia   NaN\n",
       "3       4           porto, v.n.gaia, portugal  17.0\n",
       "4       5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read users\n",
    "users = pd.read_csv('/Users/gozdeturan/Downloads/BX-CSV-Dump/BX-Users.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "# Set columns for users\n",
    "users.columns = ['UserID', 'Location', 'Age']\n",
    "# Print first 5 users to see a sample content\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>BookRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID        ISBN  BookRating\n",
       "0  276725  034545104X           0\n",
       "1  276726  0155061224           5\n",
       "2  276727  0446520802           0\n",
       "3  276729  052165615X           3\n",
       "4  276729  0521795028           6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read book ratings\n",
    "book_ratings =  pd.read_csv('/Users/gozdeturan/Downloads/BX-CSV-Dump/BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "# Set columns for book ratings\n",
    "book_ratings.columns = ['UserID', 'ISBN', 'BookRating']\n",
    "# Print first 5 book ratings to see a sample content\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering datasets\n",
    "\n",
    "I will filter the datasets to fit my computer's processor and calculate more accurate results from more valuable users. Forexample, I will discard users who didn't rate 100 books and also I will discard the books which got rating less than 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the book ratings before filtering: 1149780\n"
     ]
    }
   ],
   "source": [
    "# Before filtering\n",
    "print('Size of the book ratings before filtering: %d' % book_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the book_ratings by matching ISBN in book_ratings dataset\n",
    "# with the ISBN in books dataset. \n",
    "book_ratings = book_ratings[book_ratings.ISBN.isin(books.ISBN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the book_ratings by matching UserID in book_ratings dataset \n",
    "# with the UserID in users dataset. \n",
    "book_ratings = book_ratings[book_ratings.UserID.isin(users.UserID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean up the data, I eliminated zero ratings. \n",
    "# Zero rated book means, unrated book, which may bring incorrect results to us\n",
    "book_ratings = book_ratings[book_ratings.BookRating != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the users by matching UserID in book_ratings dataset \n",
    "# with the UserID in users dataset. \n",
    "users = users[users.UserID.isin(book_ratings.UserID)]\n",
    "\n",
    "# To make dataset small, I filtered based on location too.\n",
    "users = users[users['Location'].str.contains('usa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the users those have read at least 100 books \n",
    "user_ratings_counts = book_ratings['UserID'].value_counts()\n",
    "book_ratings        = book_ratings[book_ratings['UserID'].isin(user_ratings_counts[user_ratings_counts >= 100].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the books those have at least 200 ratings\n",
    "book_ratings_counts = book_ratings['BookRating'].value_counts()\n",
    "book_ratings        = book_ratings[book_ratings['BookRating'].isin(book_ratings_counts[book_ratings_counts >= 200].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the book ratings after filtering: 103271\n"
     ]
    }
   ],
   "source": [
    "# After filtering\n",
    "print('Size of the book ratings after filtering: %d' % book_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                          BookTitle\n",
       "0  0195153448                                Classical Mythology\n",
       "1  0002005018                                       Clara Callan\n",
       "2  0060973129                               Decision in Normandy\n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...\n",
       "4  0393045218                             The Mummies of Urumchi"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate unnecessary columns from books dataset\n",
    "books = books[['ISBN', 'BookTitle']]\n",
    "# Print first 5 items from current books dataset\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting training and test data\n",
    "\n",
    "The book_ratings data with 'ISBN', 'UserID' and 'BookRating' contains user ratings for books. This allows applying supervised learning where make possible to predict the rating of a book for the given user. Since ratings can take discrete values from 1 to 10, we can model this is a regression problem. I choose the regression model instead of the classification model. Because classification model will treat unused ratings as misclassified. For example, if a user rates a book with 7 then the ratings from 1 to 6 and 8 to 10 will be misclassified. Unlike classification model, the regression model will give penalty to the other values.\n",
    "\n",
    "In next step, I will split data into two dataset as the training data and the test data with 75% to 25% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assign X as the original book_ratings dataframe and y as the UserID column of ratings. \n",
    "X = book_ratings.copy()\n",
    "y = book_ratings['UserID']\n",
    "\n",
    "# Split into training and test datasets, along with UserID\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0000913154</th>\n",
       "      <th>0001046438</th>\n",
       "      <th>000104687X</th>\n",
       "      <th>000104799X</th>\n",
       "      <th>0001048082</th>\n",
       "      <th>0001053744</th>\n",
       "      <th>0001055607</th>\n",
       "      <th>0001056107</th>\n",
       "      <th>0001845039</th>\n",
       "      <th>0001935968</th>\n",
       "      <th>...</th>\n",
       "      <th>B000092Q0A</th>\n",
       "      <th>B00009EF82</th>\n",
       "      <th>B00009NDAN</th>\n",
       "      <th>B0000DYXID</th>\n",
       "      <th>B0000T6KHI</th>\n",
       "      <th>B0000VZEJQ</th>\n",
       "      <th>B0000X8HIE</th>\n",
       "      <th>B00013AX9E</th>\n",
       "      <th>B0001I1KOG</th>\n",
       "      <th>B000234N3A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN    0000913154  0001046438  000104687X  000104799X  0001048082  \\\n",
       "UserID                                                               \n",
       "2033           NaN         NaN         NaN         NaN         NaN   \n",
       "2110           NaN         NaN         NaN         NaN         NaN   \n",
       "2276           NaN         NaN         NaN         NaN         NaN   \n",
       "4017           NaN         NaN         NaN         NaN         NaN   \n",
       "4385           NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN    0001053744  0001055607  0001056107  0001845039  0001935968  \\\n",
       "UserID                                                               \n",
       "2033           NaN         NaN         NaN         NaN         NaN   \n",
       "2110           NaN         NaN         NaN         NaN         NaN   \n",
       "2276           NaN         NaN         NaN         NaN         NaN   \n",
       "4017           NaN         NaN         NaN         NaN         NaN   \n",
       "4385           NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN       ...      B000092Q0A  B00009EF82  B00009NDAN  B0000DYXID  \\\n",
       "UserID     ...                                                       \n",
       "2033       ...             NaN         NaN         NaN         NaN   \n",
       "2110       ...             NaN         NaN         NaN         NaN   \n",
       "2276       ...             NaN         NaN         NaN         NaN   \n",
       "4017       ...             NaN         NaN         NaN         NaN   \n",
       "4385       ...             NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN    B0000T6KHI  B0000VZEJQ  B0000X8HIE  B00013AX9E  B0001I1KOG  B000234N3A  \n",
       "UserID                                                                          \n",
       "2033           NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "2110           NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "2276           NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4017           NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4385           NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 53000 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see which UserID rated to which ISBN number we can produce a pivot table\n",
    "\n",
    "# Build the rating matrix using pivot table \n",
    "r_matrix = X_train.pivot_table(values = 'BookRating', index = 'UserID', columns = 'ISBN')\n",
    "\n",
    "# In the result we will see lots of 'NaN' which means users didn't rate all the books. \n",
    "# In next steps I will replace them with zeros to make it understandable for\n",
    "# machine learning algorithms.\n",
    "r_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0000913154</th>\n",
       "      <th>0001046438</th>\n",
       "      <th>000104687X</th>\n",
       "      <th>000104799X</th>\n",
       "      <th>0001048082</th>\n",
       "      <th>0001053744</th>\n",
       "      <th>0001055607</th>\n",
       "      <th>0001056107</th>\n",
       "      <th>0001845039</th>\n",
       "      <th>0001935968</th>\n",
       "      <th>...</th>\n",
       "      <th>B000092Q0A</th>\n",
       "      <th>B00009EF82</th>\n",
       "      <th>B00009NDAN</th>\n",
       "      <th>B0000DYXID</th>\n",
       "      <th>B0000T6KHI</th>\n",
       "      <th>B0000VZEJQ</th>\n",
       "      <th>B0000X8HIE</th>\n",
       "      <th>B00013AX9E</th>\n",
       "      <th>B0001I1KOG</th>\n",
       "      <th>B000234N3A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN    0000913154  0001046438  000104687X  000104799X  0001048082  \\\n",
       "UserID                                                               \n",
       "2033           0.0         0.0         0.0         0.0         0.0   \n",
       "2110           0.0         0.0         0.0         0.0         0.0   \n",
       "2276           0.0         0.0         0.0         0.0         0.0   \n",
       "4017           0.0         0.0         0.0         0.0         0.0   \n",
       "4385           0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "ISBN    0001053744  0001055607  0001056107  0001845039  0001935968  \\\n",
       "UserID                                                               \n",
       "2033           0.0         0.0         0.0         0.0         0.0   \n",
       "2110           0.0         0.0         0.0         0.0         0.0   \n",
       "2276           0.0         0.0         0.0         0.0         0.0   \n",
       "4017           0.0         0.0         0.0         0.0         0.0   \n",
       "4385           0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "ISBN       ...      B000092Q0A  B00009EF82  B00009NDAN  B0000DYXID  \\\n",
       "UserID     ...                                                       \n",
       "2033       ...             0.0         0.0         0.0         0.0   \n",
       "2110       ...             0.0         0.0         0.0         0.0   \n",
       "2276       ...             0.0         0.0         0.0         0.0   \n",
       "4017       ...             0.0         0.0         0.0         0.0   \n",
       "4385       ...             0.0         0.0         0.0         0.0   \n",
       "\n",
       "ISBN    B0000T6KHI  B0000VZEJQ  B0000X8HIE  B00013AX9E  B0001I1KOG  B000234N3A  \n",
       "UserID                                                                          \n",
       "2033           0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "2110           0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "2276           0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "4017           0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "4385           0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 53000 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since most of the machine learning algorithms cannot handle NaN values, \n",
    "# I replaced them with 0. \n",
    "r_matrix_temp = r_matrix.copy().fillna(0)\n",
    "r_matrix_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "I used Root Mean Squared Error (RMSE) to evaluate the performance of the algorithms.\n",
    "Below are the RMSE for three algorithms I calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the mean_squared error function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Compute the RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the RMSE score obtained on the testing set\n",
    "def score(cf_model, rating_matrix):\n",
    "    \n",
    "    # Get a list of user-isbn tuples from the testing dataset\n",
    "    id_pairs = zip(X_test['UserID'], X_test['ISBN'])\n",
    "    \n",
    "    # Predict the rating for every user-isbn tuple\n",
    "    y_pred = np.array([cf_model(user_id, isbn, rating_matrix) for (user_id, isbn) in id_pairs])\n",
    "    \n",
    "    # Extract the actual ratings given by the users in the test data\n",
    "    y_true = np.array(X_test['BookRating'])\n",
    "    \n",
    "    # Return the final RMSE score\n",
    "    return rmse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model always return 5 \n",
    "def baseline(_user_id, _isbn, _rating_matrix):\n",
    "    return 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.2431564655791156"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "print('score for baseline')\n",
    "score(baseline, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Based Collaborative Filter using Mean Ratings\n",
    "def cf_user_mean(user_id, isbn, rating_matrix):\n",
    "    # Check if isbn exists in r_matrix\n",
    "    if isbn in r_matrix:\n",
    "        # Compute the mean of all ratings\n",
    "        mean_rating = rating_matrix[isbn].mean()\n",
    "        \n",
    "    else:\n",
    "        # Default to rating 5.0 in the absence of any information\n",
    "        mean_rating = 5.0\n",
    "        \n",
    "    return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for cf_user_mean with 0 filled rating_matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.929371869275756"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we compare the score with score(baseline), \n",
    "# we will see that we get lower number which means we improved our algorithm.\n",
    "print('score for cf_user_mean with 0 filled rating_matrix:')\n",
    "score(cf_user_mean, r_matrix_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.3774\n",
      "------------\n",
      "Fold 2\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.3722\n",
      "------------\n",
      "Fold 3\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.3749\n",
      "------------\n",
      "Fold 4\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.3695\n",
      "------------\n",
      "Fold 5\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.3663\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 3.3721\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'rmse': [3.3774343393237234,\n",
       "                             3.3722296699652654,\n",
       "                             3.3748922832386459,\n",
       "                             3.3694679682551461,\n",
       "                             3.3663030337097428]})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required classes and methods from the surprise library\n",
    "from surprise import Reader, Dataset, KNNBasic, evaluate\n",
    "\n",
    "# Define a Reader object to parse the file or dataframe containing ratings\n",
    "reader = Reader()\n",
    "\n",
    "# Create the dataset to be used for building the filter\n",
    "data = Dataset.load_from_df(book_ratings, reader)\n",
    "\n",
    "# Define the algorithm object kNN\n",
    "knn = KNNBasic()\n",
    "\n",
    "# Evaluate the performance in terms of RMSE\n",
    "evaluate(knn, data, measures=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, KNN is the one which has the least Root Mean Square Error rate. \n",
    "\n",
    "|Algorithm   |RMSE       |\n",
    "|------------|-----------|\n",
    "|baseline    |4.2        |\n",
    "|cf_user_mean|5.9        |\n",
    "|KNN         |3.3        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation \n",
    "\n",
    "Our aim is to find the users similar to the user who had similar preferences given the ratings of a user. Then make predictions regarding all other books that the user has not rated but are being rated by the similar users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Create a KNN model\n",
    "def create_model(ratings):\n",
    "    model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute') \n",
    "    model_knn.fit(ratings)\n",
    "    \n",
    "    return model_knn\n",
    "\n",
    "# This function lists k similar users given the UserID and ratings matrix\n",
    "# These similarities are same as obtained via using pairwise_distances\n",
    "def list_k_similar_users(user_id, ratings, model_knn, k):\n",
    "    # Find the index of the given user_id\n",
    "    user_loc = ratings.index.get_loc(user_id)    \n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[user_loc, :].values.reshape(1, -1), n_neighbors = k + 1)\n",
    "\n",
    "    return distances, indices\n",
    "\n",
    "def recommend_books(user_id, ratings, model_knn, max_recommendations = 10):\n",
    "    # similar users based on cosine similarity\n",
    "    distances, indices = list_k_similar_users(user_id, ratings, model_knn, max_recommendations)\n",
    "    \n",
    "    similar_user_ids = []\n",
    "    # The first user_id is our user, thus I skipped the first\n",
    "    for i in range(1, len(distances.flatten())):\n",
    "        similar_user_ids.append(ratings.index[indices.flatten()[i]])\n",
    "    \n",
    "    # Find most rated by books from the user's neighbours(smilar users)\n",
    "    temp_book_ratings = book_ratings[book_ratings['UserID'].isin(similar_user_ids)]\n",
    "    \n",
    "    # Discard the books already read by the user\n",
    "    temp_book_ratings = temp_book_ratings[~book_ratings['UserID'].isin([user_id])]\n",
    "    \n",
    "    # Find the average BookRatings grouped by ISBN then take most rated top 10(max_recommendations)\n",
    "    temp_book_ratings = temp_book_ratings.groupby(['ISBN'])['BookRating'].mean().nlargest(max_recommendations)\n",
    "\n",
    "    print('Following books are recommended for the given UserID(%s)' % user_id)\n",
    "    print('--------------------------------')\n",
    "    for isbn, _average_rating in temp_book_ratings.iteritems():\n",
    "        book_index = (books.index[books['ISBN'] == isbn])[0]\n",
    "        print('%s %s' % (isbn, books.BookTitle[book_index]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following books are recommended for the given UserID(275970)\n",
      "--------------------------------\n",
      "0060012366 The Wee Free Men (Bccb Blue Ribbon Fiction Books (Awards))\n",
      "0060013117 Night Watch\n",
      "006001315X Monstrous Regiment (Pratchett, Terry)\n",
      "0060175966 The Professor and the Madman\n",
      "0060392452 Stupid White Men ...and Other Sorry Excuses for the State of the Nation!\n",
      "0060803444 Is Sex Necessary? : Or Why You Feel the Way You Do\n",
      "0060920084 The Lost Continent: Travels in Small-Town America\n",
      "0060923245 Sweet Hereafter Movie Tie-In : A Novel\n",
      "0060925493 Feather Crowns\n",
      "0060929847 Our Town: A Play in Three Acts (Perennial Classics)\n",
      "\n",
      "\n",
      "Following books are recommended for the given UserID(4017)\n",
      "--------------------------------\n",
      "0060558199 Save Karyn : One Shopaholic's Journey to Debt and Back\n",
      "0060974060 Friday Night Lights: A Town, a Team, and a Dream\n",
      "0060981180 Mariette in Ecstasy\n",
      "0062508164 Truth or Dare : Encounters with Power, Authority, and Mystery\n",
      "0064400557 Charlotte's Web (Trophy Newbery)\n",
      "0064400972 Betsy-Tacy and Tib (Betsy-Tacy)\n",
      "0064400980 Betsy and Tacy Go Downtown (Betsy-Tacy)\n",
      "0064400999 Betsy and Tacy Go Over the Big Hill (Betsy-Tacy)\n",
      "0064401103 Heaven to Betsy\n",
      "0064401111 Betsy in Spite of Herself (Harper Trophy Book)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a reusable model\n",
    "model_knn = create_model(r_matrix_temp)\n",
    "\n",
    "# Recommend books to a random user\n",
    "recommend_books(275970, r_matrix_temp, model_knn, 10)\n",
    "\n",
    "# Recommend books to another random user\n",
    "recommend_books(4017, r_matrix_temp, model_knn, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, I built a book recommendation system which recommends **desired number of books** for the given user according to **the average ratings of the similar users**. It is possible to get better results by applying data cleaning and pruning operations to the given datasets. Also, possible to use other algorithms and choose the best one. I tried to analyze the data before starting to process. For future case study, user's age and book's publisher information could be used to have better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
